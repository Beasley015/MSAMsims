#Create a vector of lambdas
lambdas <- seq(0, 5, length.out = 10)
#Write functions for multiple lasso regressions -------------------------------
run.lasso <- function(x, y, lambdas){
for(i in 1:length(lambdas)){
lasso.mod <- list()
lasso.mod[[i]] <- glmnet(x = x, y = y, alpha = 0,
lambda = lambdas[i])
return(lasso.mod)
}
}
#Create a vector of lambdas
lambdas <- seq(0, 5, length.out = 10) #lambdas must be positive
#Write functions for multiple lasso regressions -------------------------------
run.lasso <- function(x, y, lambdas){
for(i in 1:length(lambdas)){
lasso.mod <- list()
lasso.mod[[i]] <- glmnet(x = x, y = y, alpha = 0,
lambda = lambdas[i])
return(lasso.mod)
}
}
lassos <- run.lasso(x = swiss.x, y = swiss.y, lambdas = lambdas)
swiss.x <- model.matrix(Fertility~., swiss)[,-1]
#Write functions for multiple lasso regressions -------------------------------
run.lasso <- function(x, y, lambdas){
for(i in 1:length(lambdas)){
lasso.mod <- list()
lasso.mod[[i]] <- glmnet(x = x, y = y, alpha = 0,
lambda = lambdas[i])
return(lasso.mod)
}
}
lassos <- run.lasso(x = swiss.x, y = swiss.y, lambdas = lambdas)
View(lassos)
#Write functions for multiple lasso regressions -------------------------------
run.lasso <- function(x, y, lambdas){
for(i in 1:length(lambdas)){
lasso.mod <- list()
lasso.mod[[i]] <- glmnet(x = x, y = y, alpha = 0,
lambda = lambdas[i])
}
return(lasso.mod)
}
lassos <- run.lasso(x = swiss.x, y = swiss.y, lambdas = lambdas)
View(lassos)
lassos[[1]]
library(glmnet)
swiss <- swiss
swiss.y <- swiss$Fertility
swiss.x <- model.matrix(Fertility~., swiss)[,-1]
#Create a vector of lambdas
lambdas <- seq(0, 5, length.out = 10) #lambdas must be positive
#Write functions for multiple lasso regressions -------------------------------
run.lasso <- function(x, y, lambdas){
for(i in 1:length(lambdas)){
lasso.mod <- list()
lasso.mod[[i]] <- glmnet(x = x, y = y, alpha = 0,
lambda = lambdas[i])
}
return(lasso.mod)
}
lassos <- run.lasso(x = swiss.x, y = swiss.y, lambdas = lambdas)
lasso.mod[[1]] <- glmnet(x = x, y = y, alpha = 0,
lambda = lambdas[1])
lasso.mod[[1]] <- glmnet(x = swiss.x, y = swiss.y, alpha = 0,
lambda = lambdas[1])
lasso.mod <- list()
lasso.mod[[1]] <- glmnet(x = swiss.x, y = swiss.y, alpha = 0,
lambda = lambdas[1])
#Write functions for multiple lasso regressions -------------------------------
run.lasso <- function(x, y, lambdas){
lass.mod <- list()
for(i in 1:length(lambdas)){
lasso.mod[[i]] <- glmnet(x = x, y = y, alpha = 0,
lambda = lambdas[i])
}
return(lasso.mod)
}
lassos <- run.lasso(x = swiss.x, y = swiss.y, lambdas = lambdas)
lassos[[1]]
summary(lassos[[1]])
summary(lasso.mod)
lasso.mod
lasso.mod <- glmnet(x = swiss.x, y = swiss.y, alpha = 0,
lambda = lambdas[1])
lasso.mod$beta
lasso.mod$call
lasso.mod <- glmnet(x = swiss.x, y = swiss.y, alpha = 0,
lambda = lambdas[10])
lasso.mod$beta
### Step 1: Load and initialize the arcgisbinding
library(arcgisbinding)
arc.check_product()
install.packages("mclust")
library(sp)
library(mclust)
### Step 4: Load the billboard faces dataset
d <- arc.open(path = 'c:\\EsriTraining\\R-ArcGISBridge\\data.gdb\\Billboard_Faces')
library(tidyverse)
### Step 5: Select a subset data from the loaded dataset
dsub <- select(d, WIDTH, HEIGHT, OBJECTID)
d %>%
as.data.frame()
d %>%
arc.select(c('WIDTH','HEIGHT','OBJECTID'),
where_clause = "WIDTH > 25 AND HEIGHT > 11")
### Step 4: Load the billboard faces dataset
d <- arc.open(path = 'c:\\EsriTraining\\R-ArcGISBridge\\data.gdb\\Billboard_Faces')
d %>%
arc.select(c('WIDTH','HEIGHT','OBJECTID'),
where_clause = "WIDTH > 25 AND HEIGHT > 11") %>%
{. ->> data}
d %>%
arc.select(c('WIDTH','HEIGHT','OBJECTID'),
where_clause = "WIDTH > 25 AND HEIGHT > 11")
### Step 4: Load the billboard faces dataset
d <- arc.open(path = 'c:\\EsriTraining\\R-ArcGISBridge\\data.gdb\\Billboard_Faces')
data <- arc.select(c('WIDTH','HEIGHT','OBJECTID'),
where_clause = "WIDTH > 25 AND HEIGHT > 11")
### Step 4: Load the billboard faces dataset
d <- arc.open(path = 'c:\\EsriTraining\\R-ArcGISBridge\\data.gdb\\Billboard_Faces')
data <- arc.select(c('WIDTH','HEIGHT','OBJECTID'),
where_clause = "WIDTH > 25 AND HEIGHT > 11")
data <- arc.select(d, c('WIDTH','HEIGHT','OBJECTID'),
where_clause = "WIDTH > 25 AND HEIGHT > 11")
### Step 6: Get the shape object from the selected subset data
shape <- arc.shape(data)
### Step 7: Pull the x and y coordinate values for each record and populate a dataframe
xy <- data.frame(shape$x, shape$y)
patternBIC <- mclustBIC(data.xy)
### takes  the cluster results, and the data.xy dataframe and produces a summary
patternModel <- summary(patternBIC, data.xy)
### returns a list of probabilities
n <- patternModel$G
cond_probs <- lapply(1:n, function(i) patternModel$z[,i])
### determines the best model from clustering
bestModel <- mclustModel(data.xy, patternBIC)
### Calls the create.ellipse function
polygons <- create.ellipses(bestModel)
### pulls the mean value parameters from the bestmodel
mu <- bestModel$parameters$mean
### Step 8: Create a SpatialPolygonsDataFrame object to hold the polygon
### Step 9: Convert an sp object to ArcGIS object
### Step 10: Write the output of the clustering to a new feature class
### utility functions for creating the ellipses
create.ellipses <- function(bestModel)
{
n <- bestModel$G
mu <- bestModel$parameters$mean
sigma <- bestModel$parameters$variance$sigma
cls.polygons <- lapply(1:n, function(i)
{
xy <- make.ellipse(mu = mu[,i], sigma = sigma[, , i])
name <- paste0("ellipse", i)
Polygons(list(Polygon(xy)), name)
})
SpatialPolygons(cls.polygons, 1:n, proj4string=sp::CRS())
}
make.ellipse <- function(mu, sigma, k = 60)
{
p <- length(mu)
if(p != 2)
stop("only two-dimensional case is available")
if(any(unique(dim(sigma)) != p))
stop("mu and sigma are incompatible")
ev <- eigen(sigma, symmetric = TRUE)
s <- sqrt(rev(sort(ev$values)))
v <- t(ev$vectors[, rev(order(ev$values))])
theta <- (0:k) * (2*pi/k)
x <- s[1] * cos(theta)
y <- s[2] * sin(theta)
xy <- cbind(x,y)
xy <- xy %*% v
cbind(xy[,1] + mu[1], xy[,2] + mu[2])
}
?check_product
?check_product()
??check_product
install.packages("lars")
#Load packages and data ---------------------------------------------------------
library(lars)
library(glmnet)
diabetes <- diabetes
diabetes <- diabetes()
#Load packages and data ---------------------------------------------------------
library(lars)
diabetes <- diabetes()
diabetes <- diabetes
diabetes
data(diabetes)
#Run a lm for benchmark comparisons
bench.model <- lm(data = diabetes, formula = y ~ x)
summary(bench.model)
#Plot coefficient shrinkage using glmnet ----------------------------------------
shrink <- glmnet(x = diabetes$x, y = diabetes$y)
plot.glmnet(x = shrink, xvar = "norm", label = T)
plot.glmnet(x = shrink, xvar = "lambda", label = T)
#Find the value of lambda that minimizes mean cross validation error ------------
cverror <- cv.glmnet(x = diabetes$x, y = diabetes$y, alpha = 1)
plot.cv.glmnet(x = cverror)
cverror$lambda.min
#Use the above lambda value to get the estimated beta (coefficient) matrix ------
shrink.fit <- glmnet(x = diabetes$x, y = diabetes$y, lambda = cverror$lambda.min)
shrink.fit$beta
#Find the value of lambda that minimizes mean cross validation error ------------
cverror <- cv.glmnet(x = diabetes$x, y = diabetes$y, alpha = 1, lambda = 1000)
#Find the value of lambda that minimizes mean cross validation error ------------
cverror <- cv.glmnet(x = diabetes$x, y = diabetes$y, alpha = 1, nlambda = 1000)
plot.cv.glmnet(x = cverror)
cverror$lambda.min
#Use the above lambda value to get the estimated beta (coefficient) matrix ------
shrink.fit <- glmnet(x = diabetes$x, y = diabetes$y, lambda = cverror$lambda.min)
shrink.fit$beta
#Use a larger value of lambda to further reduce the number of predictors --------
cverror$lambda.1se
shrink.fit2 <- glmnet(x - diabetes$x, y = diabetes$y, lambda = cverror$lambda.1se)
shrink.fit2 <- glmnet(x = diabetes$x, y = diabetes$y, lambda = cverror$lambda.1se)
shrink.fit2$beta
install.packages("FactoMineR")
install.packages("factoextra")
library(FactoMineR)
library(FactoMineR)
library(factoextra)
data("iris")
head(iris)
iris2 <- iris[,1:4]
#Run the PCA
iris.pca <- PCA(iris2, scale.unit = T, graph = F)
#Look at eigenvalues
iris.pca$eig
#scree plot for visualization
fviz_screeplot(iris.pca, ncp = 4)
plot.PCA(iris.pca, axes = c(1,2), choix = "var")
#biplot
fviz_pca(iris.pca)
#Clean it up
fviz_pca_var(iris.pca, col.var = "contrib")
#Clean it up with a scale showing relative contributions
fviz_pca_var(iris.pca, col.var = "contrib")+
scale_color_gradient2(low = "blue", mid = "steelblue", high = "red",
midpoint = 25)+
theme_bw()
#individual data points without lables
fviz_pca_ind(iris.pca, label = "none")
#add some color to make clusters more informative
fviz_pca_ind(iris.pca, label = "none", habillage = iris$Species)
#add some color to make clusters more informative
fviz_pca_ind(iris.pca, label = "none", habillage = iris$Species, ellipseCA(0.95))
#add some color to make clusters more informative
fviz_pca_ind(iris.pca, label = "none", habillage = iris$Species, ellipse.level = 0.95
)
#add some color to make clusters more informative
fviz_pca_ind(iris.pca, label = "none", habillage = iris$Species, addEllipses = T
ellipse.level = 0.95)
#add some color to make clusters more informative
fviz_pca_ind(iris.pca, label = "none", habillage = iris$Species, addEllipses = T,
ellipse.level = 0.95)
fviz_pca_biplot(iris.pca, geom.ind = "point", fill.ind = iris$Species,
col.ind = "black", addEllipses = T, col.var = "contrib")
#Creating web-based graphs with plotly----------------------------------
library(plotly)
install.packages("plotly")
#Creating web-based graphs with plotly----------------------------------
#load packas
library(plotly)
data(mpg)
data <- mpg
p <- plot_ly(data = mpg, x = ~displ, y = ~cty)
p
#plotly also interacts with ggplot with ggplotly
p2 <- ggplotly(data = mpg, aes(x = displ, y = cty))
#plotly also interacts with ggplot with ggplotly
p2 <- ggplot(data = mpg, aes(x = displ, y = cty))+
geom_point()
ggplotly(p2)
#plotly also interacts with ggplot with ggplotly
p2 <- ggplot(data = mpg, aes(x = displ, y = cty, color = manufacturer))+
geom_point()
ggplotly(p2)
head(txhousing)
tx <- txhousing
allCities <- txhousing %>%
group_by(city) %>%
plot_ly(x = ~date, y = ~median)
allcities
allCities
#3d plots
plot_ly(data = iris, x = ~sepal.length, y = ~sepal.width, z = ~petal.length,
type = "scatter3d", mode = "markers", size = petal.width, color = ~Species)
#3d plots
plot_ly(data = iris, x = ~Sepal.Length, y = ~Sepal.Width, z = ~Petal.Length,
type = "scatter3d", mode = "markers", size = Petal.Width, color = ~Species)
#3d plots
plot_ly(data = iris, x = ~Sepal.Length, y = ~Sepal.Width, z = ~Petal.Length,
type = "scatter3d", mode = "markers", size = ~Petal.Width, color = ~Species)
#Animations
df <- data.frame(x = c(1:5, 4:1), y = c(1:5, 4:1), f = (a:9))
#Animations
df <- data.frame(x = c(1:5, 4:1), y = c(1:5, 4:1), f = (1:9))
p <- plot_ly(data = df, x = ~x, y = ~y, frame = ~f, type = "scatter",
transition = ~f, mode = "markers", showleged = T)
p
install.packages("Plot3D")
install.packages("plot3D")
install.packages("plot3Drgl")
install.packages("diffdf")
install.packages("ggtree")
install.packages"treeio"
install.packages("treeio")
install.packages(emojifont)
install.packages("emojifont")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("ggtree", version = "3.8")
library(betapart)
ggplot(data = spec.comp, aes(x = Rank))+
geom_point(aes(y = Estimated, color = "Estimated"))+
geom_smooth(aes(y = Estimated, fill = "Estimated", color = "Estimated"),
show.legend = F, alpha = 0.25)+
geom_point(aes(y = Observed, color = "Observed"))+
geom_smooth(aes(y = Observed, fill = "Observed", color = "Observed"), alpha = 0.25)+
geom_point(aes(y = True, color = "True"))+
geom_smooth(aes(y = Observed, fill = "True", color = "True"), alpha = 0.25)+
scale_fill_manual(breaks = c("Estimated", "Observed", "True"),
values = c("blue", "black", "red"), guide = F)+
scale_color_manual(breaks = c("Estimated", "Observed", "True"),
values = c("blue", "black", "red"))+
theme_bw()
library(vcdExtra)
library(vegan)
library(R2OpenBUGS)
library(abind)
library(tidyverse)
setwd("c:/users/beasley/dropbox/MSAMsims")
set.seed(15) #ensures sim is same each time
#Prelim data: sites, survey, seed -----------------------------------------------
J <- 30 #sites
K <- 3 #surveys per site
specs<-11 #Number of species
Ks<-rep(K, J)
#Ks is a vector of length J indicationg # of sampling periods per site
#simulated values for covs would go here
#Simulating abundance data --------------------------------------------------
mean.lambdas <- rlogseries(specs, 0.75)
#Draw lambdas from a logseries distribution
alpha0 <- log(mean.lambdas) #log-scale intercept
#abundance responses to any covariates would go here as alpha1, alpha2, etc
log.lambdas <- alpha0  #this is your log link function. add covs here
lambdas <- exp(log.lambdas)  #inverse link transformation
#most of these steps won't matter until covs are added
#create list of abundance vectors
nlist<-list()
for(a in 1:specs){
nlist[[a]] <- rpois(n = J, lambda = lambdas[a])
}
ns<-do.call(rbind, nlist) #turn abundance vectors into abundance matrix
rowSums(ns) #total abundances
rotate.ns<-t(ns) #I might need an inverted matrix later
#Simulated observation process ------------------------------------------
some.det <- runif(n = specs-1, min = 0, max = 0.6)#simulate mean detection probs
#These are fairly low det probs
no.det <- 0
#Two species will not be detected
mean.det <- c(some.det, no.det)
beta0<-qlogis(mean.det) #put it on logit scale
#responses to detection covs would go here
logit.p<-beta0 #logit link function. Det covs go here
p <- plogis(logit.p) #Transform it back
#Simulate observation data
L<-list()
for(b in 1:specs){
y<-matrix(NA, ncol = K, nrow = J)
for(a in 1:K){
y[,a]<-rbinom(n = J, size = ns[b,], prob = p[b])
}
L[[b]]<-y
}
#I suppose I could make that a function but I'm lazy
#Smash it into array
obsdata<-array(as.numeric(unlist(L)), dim=c(J, K, specs-1))
#Nondetected species were removed from observation data
#Number of observed species
n <- length(some.det)
#Augment data with all-zero matrices
n.aug <- 2
augmats <- array(0, dim = c(J, K, n.aug))
augdata <- abind(obsdata, augmats, along = 3)
maxobs <- apply(augdata, c(1,3), max)
augmodel <- readRDS(file = "augsanscovs.RDS")
# Model evaluation: regional and site-level richness ----------------------------
Ns <- augmodel$sims.list$N
mean(Ns); quantile(Ns, c(0.025, 0.25, 0.75, 0.975))
ggplot()+
geom_histogram(aes(x = Ns), binwidth = 1)
# Model evaluation: posterior distributions -------------------------------------
post.abund <- augmodel$sims.list$mu.a0
hist(post.abund)
post.det <- augmodel$sims.list$mu.b0
hist(post.det)
#detection isn't bimodal, so that's good
# Compare observed, estimated, and true abundance ------------------------------
Zs <- augmodel$sims.list$Z
spec.abunds <- apply(Zs, c(1,3), sum)
spec.mean <- apply(spec.abunds[,-12], 2, mean)
spec.obs <- apply(t(maxobs[,-12]), 1, sum)
spec.true <- rowSums(ns)
spec.comp <- data.frame(Rank = rank(spec.true), Estimated = spec.mean,
Observed = spec.obs, True = spec.true)
ggplot(data = spec.comp, aes(x = Rank))+
geom_point(aes(y = Estimated, color = "Estimated"))+
geom_smooth(aes(y = Estimated, fill = "Estimated", color = "Estimated"),
show.legend = F, alpha = 0.25)+
geom_point(aes(y = Observed, color = "Observed"))+
geom_smooth(aes(y = Observed, fill = "Observed", color = "Observed"), alpha = 0.25)+
geom_point(aes(y = True, color = "True"))+
geom_smooth(aes(y = Observed, fill = "True", color = "True"), alpha = 0.25)+
scale_fill_manual(breaks = c("Estimated", "Observed", "True"),
values = c("blue", "black", "red"), guide = F)+
scale_color_manual(breaks = c("Estimated", "Observed", "True"),
values = c("blue", "black", "red"))+
theme_bw()
ggplot(data = spec.comp, aes(x = Rank))+
geom_point(aes(y = Estimated, color = "Estimated"))+
geom_smooth(aes(y = Estimated, fill = "Estimated", color = "Estimated"),
show.legend = F, alpha = 0.25)+
geom_point(aes(y = Observed, color = "Observed"))+
geom_smooth(aes(y = Observed, fill = "Observed", color = "Observed"), alpha = 0.25)+
geom_point(aes(y = True, color = "True"))+
geom_smooth(aes(y = True, fill = "True", color = "True"), alpha = 0.25)+
scale_fill_manual(breaks = c("Estimated", "Observed", "True"),
values = c("blue", "black", "red"), guide = F)+
scale_color_manual(breaks = c("Estimated", "Observed", "True"),
values = c("blue", "black", "red"))+
theme_bw()
#Sites
site.abund <- apply(Zs, c(1,2), sum)
site.mean <- apply(site.abund, 2, mean)
site.true <- colSums(ns)
site.obs <- apply(t(maxobs), 2, sum)
site.comp <- data.frame(Rank = rank(site.true), True = site.true,
Observed = site.obs, Estimated = site.mean)
ggplot(data = site.comp, aes(x = Rank))+
geom_point(aes(y = True, color = "True"))+
geom_smooth(aes(y = True, color = "True", fill = "True"))+
geom_point(aes(y = Observed, color = "Observed"))
ggplot(data = site.comp, aes(x = Rank))+
geom_point(aes(y = True, color = "True"))+
geom_smooth(aes(y = True, color = "True", fill = "True"))+
geom_point(aes(y = Observed, color = "Observed"))+
geom_smooth(aes(y = Observed, color = "Observed", fill = "Observed"))+
geom_point(aes(y = Estimated, color = "Estimated"))+
geom_smooth(aes(y = Estimated, color = "Estimated", fill = "Estimated"))
ggplot(data = site.comp, aes(x = Rank))+
geom_point(aes(y = True, color = "True"))+
geom_smooth(aes(y = True, color = "True", fill = "True"))+
geom_point(aes(y = Observed, color = "Observed"))+
geom_smooth(aes(y = Observed, color = "Observed", fill = "Observed"))+
geom_point(aes(y = Estimated, color = "Estimated"))+
geom_smooth(aes(y = Estimated, color = "Estimated", fill = "Estimated"))+
scale_color_manual(breaks = c("True", "Estimated", "Observed"), values =
c("blue", "black", "red
"))
ggplot(data = site.comp, aes(x = Rank))+
geom_point(aes(y = True, color = "True"))+
geom_smooth(aes(y = True, color = "True", fill = "True"))+
geom_point(aes(y = Observed, color = "Observed"))+
geom_smooth(aes(y = Observed, color = "Observed", fill = "Observed"))+
geom_point(aes(y = Estimated, color = "Estimated"))+
geom_smooth(aes(y = Estimated, color = "Estimated", fill = "Estimated"))+
scale_color_manual(breaks = c("True", "Estimated", "Observed"), values =
c("blue", "black", "red"))
ggplot(data = site.comp, aes(x = Rank))+
geom_point(aes(y = True, color = "True"))+
geom_smooth(aes(y = True, color = "True", fill = "True"))+
geom_point(aes(y = Observed, color = "Observed"))+
geom_smooth(aes(y = Observed, color = "Observed", fill = "Observed"))+
geom_point(aes(y = Estimated, color = "Estimated"))+
geom_smooth(aes(y = Estimated, color = "Estimated", fill = "Estimated"))+
scale_color_manual(breaks = c("True", "Estimated", "Observed"), values =
c("blue", "black", "red"))+
scale_fill_manual(breaks = c("True", "Estimated", "Observed"), values =
c("blue", "black", "red"), guide = F)
ggplot(data = site.comp, aes(x = Rank))+
geom_point(aes(y = True, color = "True"))+
geom_smooth(aes(y = True, color = "True", fill = "True"))+
geom_point(aes(y = Observed, color = "Observed"))+
geom_smooth(aes(y = Observed, color = "Observed", fill = "Observed"))+
geom_point(aes(y = Estimated, color = "Estimated"))+
geom_smooth(aes(y = Estimated, color = "Estimated", fill = "Estimated"))+
scale_color_manual(breaks = c("True", "Estimated", "Observed"), values =
c("blue", "black", "red"))+
scale_fill_manual(breaks = c("True", "Estimated", "Observed"), values =
c("blue", "black", "red"), guide = F)+
theme_bw()
install.packages("shiny")
#Make sure estimates aren't biased at high or low abundances --------------------
specmod <- lm(data = spec.comp, True~Estimated)
summary(specmod)
#Make sure estimates aren't biased at high or low abundances --------------------
specmod <- lm(data = spec.comp, Estimated~True)
specmod
summary(specmod)
ggplot(data = spec.comp, aes(x = True, y = Estimated))+
geom_point()+
geom_smooth()
#By site
sitemod <- lm(data = site.comp, Estimated~True)
summary(sitemod)
ggplot(data = site.comp, aes(x = True, y = Estimated))+
geom_point()+
geom_smooth()
